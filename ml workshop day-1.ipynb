{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b9a6d7-26d5-4d4b-8023-d883f6cf441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dex.no</th>\n",
       "      <th>name</th>\n",
       "      <th>type1</th>\n",
       "      <th>type2</th>\n",
       "      <th>evolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bulbasaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ivysaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>venasaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>charmander</td>\n",
       "      <td>fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>charmelon</td>\n",
       "      <td>fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>charizard</td>\n",
       "      <td>fire</td>\n",
       "      <td>flying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>squirtle</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>wartortle</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>blastoise</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>caterpie</td>\n",
       "      <td>bug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>medapod</td>\n",
       "      <td>bug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>butterfree</td>\n",
       "      <td>bug</td>\n",
       "      <td>flying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>weedle</td>\n",
       "      <td>bug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>kakuna</td>\n",
       "      <td>bug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>beedrill</td>\n",
       "      <td>bug</td>\n",
       "      <td>flying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dex.no        name  type1   type2  evolution\n",
       "0        1   bulbasaur  grass  poison          3\n",
       "1        2     ivysaur  grass  poison          3\n",
       "2        3    venasaur  grass  poison          3\n",
       "3        4  charmander   fire     NaN          3\n",
       "4        5   charmelon   fire     NaN          3\n",
       "5        6   charizard   fire  flying          3\n",
       "6        7    squirtle  water     NaN          3\n",
       "7        8   wartortle  water     NaN          3\n",
       "8        9   blastoise  water     NaN          3\n",
       "9       10    caterpie    bug     NaN          3\n",
       "10      11     medapod    bug     NaN          3\n",
       "11      12  butterfree    bug  flying          3\n",
       "12      13      weedle    bug     NaN          3\n",
       "13      14      kakuna    bug     NaN          3\n",
       "14      15    beedrill    bug  flying          3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df= pd.read_csv(r\"C:\\Users\\Administrator\\Documents\\pokedex.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aadbd685-7f1a-445c-b33d-5368f14b61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import KBinsDiscretizer,LabelEncoder\n",
    "def prepare_data():\n",
    "    iris = load_iris()\n",
    "    x = iris.data\n",
    "    y = iris.target\n",
    "    discretizer = KBinsDiscretizor(n_bins=3,encode=\"ordinal\",statergy=\"uniform\")\n",
    "    X_binned = discretizer.fit_transform(x)\n",
    "    categories = ['LOW','MEDIUM','HIGH']\n",
    "    df = pd.DataFrame(X_binned,colums=iris.feature_names)\n",
    "    df = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa953f80-d4aa-4596-bd10-10daf017c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import KBinsDiscretizer,LabelEncoder\n",
    "def prepare_data():\n",
    "    iris = load_iris()\n",
    "    x = iris.data\n",
    "    y = iris.target\n",
    "    discretizer = KBinsDiscretizor(n_bins=3,encode=\"ordinal\",statergy=\"uniform\")\n",
    "    X_binned = discretizer.fit_transform(x)\n",
    "    categories = ['LOW','MEDIUM','HIGH']\n",
    "    df = pd.DataFrame(X_binned,colums=iris.feature_names)\n",
    "    for col in df_columns:\n",
    "        df[col] = df[col].apply(lambda x: cat[int(x)])\n",
    "        df['target']==['YES' if label==0 else 'NO' for label in y]\n",
    "        return df\n",
    "def encode_data(df):\n",
    "    x = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    k_list = []\n",
    "    for col in x_columns:\n",
    "        k = LabelEncoder()\n",
    "        x[col] = k.fit_trnsform(x[col])\n",
    "        k_list.append(k)\n",
    "        label_encoder= LabelEncoder()\n",
    "        y = label_encoder.fit_transform(y)     #yes=1 and no=0\n",
    "    return X.values,y\n",
    "def consistent(hypothesis,instance):\n",
    "    return all(h=='?' or h == val for h,val in zip(hypothesis,instances))\n",
    "def generalize_S(S,instance):\n",
    "    for i in range(len(S)):\n",
    "        if S[i] ==0:\n",
    "            S[i] = instance[i]\n",
    "        elif S[i] != instance[i]:\n",
    "            S[i] = '?'\n",
    "    return S\n",
    "def specialize_G(G,S,instance):\n",
    "    new_G = []\n",
    "    for g in G:\n",
    "        if consistent(g,instance):\n",
    "            for i in range(len(g)):\n",
    "                if g[i] == \"?\":\n",
    "                    if S[i] != instance[i]:\n",
    "                        new_hypo = g.copy()\n",
    "                        new_hypo[i] = s[i]\n",
    "                        if new_hypo not in new_G:\n",
    "                            new_G.append(new_hypo)\n",
    "    return new_G\n",
    "def candidate_elimination(x,y,n_values):\n",
    "    S = ['0']*X.shape[1]\n",
    "    G = [['?']*x.shape[1]]\n",
    "    \n",
    "    for xi,yi in zip(X,y):\n",
    "        if yi ==1:\n",
    "            S = generalize_S(S ,xi)\n",
    "            g =[g for g in g if G if consistent(g ,S)]\n",
    "        else:\n",
    "            G = specialize_G(G, S, xi, n_values)\n",
    "    return S,G\n",
    "    df =prepare_data()\n",
    "    x,y= encode_data(df)\n",
    "    S_final, G_final = candidate_elimination(X,y)\n",
    "    \n",
    "    print(\"Final specific hypothesis (S):\",S_final)\n",
    "    print(\"Final general Hypothesis(G):\")\n",
    "    for g in G_final:\n",
    "        print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eac028-9576-413d-8553-2d0362afd4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import KBinsDiscretizer, LabelEncoder\n",
    "\n",
    "def prepare_data():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    \n",
    "    discretizer = KBinsDiscretizer(n_bins=3, encode=\"ordinal\", strategy=\"uniform\")\n",
    "    X_binned = discretizer.fit_transform(X)\n",
    "    categories = ['LOW', 'MEDIUM', 'HIGH']\n",
    "    df = pd.DataFrame(X_binned, columns=iris.feature_names)\n",
    "    df['target'] = ['YES' if label == 0 else 'NO' for label in y]\n",
    "    return df\n",
    "\n",
    "def encode_data(df):\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    k_list = []\n",
    "    for col in X.columns:\n",
    "        k = LabelEncoder()\n",
    "        X[col] = k.fit_transform(X[col])\n",
    "        k_list.append(k)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)  # YES=1 and NO=0\n",
    "    \n",
    "    return X.values, y\n",
    "\n",
    "def consistent(hypothesis, instance):\n",
    "    return all(h == '?' or h == val for h, val in zip(hypothesis, instance))\n",
    "\n",
    "def generalize_S(S, instance):\n",
    "    for i in range(len(S)):\n",
    "        if S[i] == 0:\n",
    "            S[i] = instance[i]\n",
    "        elif S[i] != instance[i]:\n",
    "            S[i] = '?'\n",
    "    return S\n",
    "\n",
    "def specialize_G(G, S, instance, n_values):\n",
    "    new_G = []\n",
    "    for g in G:\n",
    "        if consistent(g, instance):\n",
    "            for i in range(len(g)):\n",
    "                if g[i] == \"?\":\n",
    "                    if S[i] != instance[i]:\n",
    "                        new_hypo = g.copy()\n",
    "                        new_hypo[i] = instance[i]\n",
    "                        if new_hypo not in new_G:\n",
    "                            new_G.append(new_hypo)\n",
    "    return new_G\n",
    "\n",
    "def candidate_elimination(X, y, n_values):\n",
    "    S = ['0'] * X.shape[1]\n",
    "    G = [['?'] * X.shape[1]]\n",
    "    \n",
    "    for xi, yi in zip(X, y):\n",
    "        if yi == 1:\n",
    "            S = generalize_S(S, xi)\n",
    "            G = [g for g in G if consistent(g, S)]\n",
    "        else:\n",
    "            G = specialize_G(G, S, xi, n_values)\n",
    "    return S, G\n",
    "\n",
    "df = prepare_data()\n",
    "X, y = encode_data(df)\n",
    "n_values = 3\n",
    "S_final, G_final = candidate_elimination(X, y, n_values)\n",
    "\n",
    "print(\"Final specific hypothesis (S):\", S_final)\n",
    "print(\"Final general hypothesis (G):\")\n",
    "for g in G_final:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7319f6e-24a9-4485-a64d-eba0f199a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset/playgolf_data.csv\")\n",
    "print(\"\\n Given Play Golf Dataset:\\n\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b8412d5-f0a8-4046-a878-45be65a2482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def entropy(probs):\n",
    "    return sum([-prob*math.log(prob, 2) for prob in probs])\n",
    "def entropy_of_list(ls, value):\n",
    "    from collections import Counter\n",
    "    total_instances = len(ls)\n",
    "    print(\"\\n total no of  instances/records associated with'{0}' is -> {1}\".format(value,total_instances))\n",
    "    cnt = Counter(x for x in ls)\n",
    "    print('\\ntargetattribute class count(yes/no)=',dict(cnt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea1d22-73fa-4a64-a0e4-2f7f8bfa6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    probs = [x / total_instances for x in cnt.values()]\n",
    "    print(\"\\nclasses->\", max(cnt), min(cnt))\n",
    "    print(\"\\nProbabilities of class 'p'='{0}' -> {1}\")\n",
    "    class count(yes/no)=',dict(cnt))\n",
    "\n",
    "    s for x in cnt.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb0d8a9-594d-4d54-bf41-8f8542eb07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(df,split_attribute,target_attribute,battr):\n",
    "    print(\"\\n\\n----- information Gain Calculation of:\",splite_attribute)\n",
    "    df_split= sf.groupby(split_attribute)\n",
    "    glist=[]\n",
    "    for gname,group in df_split:\n",
    "        print('Grouped Attribute Values \\n',group)\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "        glist.append(gname)\n",
    "    glist.reverse()\n",
    "    nobs = len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
